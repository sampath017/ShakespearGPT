{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8460534f-7fd6-43be-b538-25576f9d8f58",
      "metadata": {
        "id": "8460534f-7fd6-43be-b538-25576f9d8f58"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import wandb\n",
        "import torch\n",
        "\n",
        "from pathlib import Path\n",
        "from lightning.pytorch import (\n",
        "    callbacks,\n",
        "    loggers,\n",
        "    Trainer,\n",
        "    utilities\n",
        ")\n",
        "\n",
        "from model import Model\n",
        "from data_module import ShakespearDataModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "79f93a6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "batch_size = 64  # how many independent sequences will we process in parallel?\n",
        "block_size = 8  # what is the maximum context length for predictions?\n",
        "learning_rate = 3e-4\n",
        "n_embd = 9\n",
        "n_head = 3\n",
        "n_layer = 6\n",
        "dropout = 0.0\n",
        "head_size = n_embd // n_head\n",
        "# ------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "764ab7d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.getLogger(\"lightning.pytorch\").setLevel(logging.INFO)\n",
        "root_path = Path('../')\n",
        "dm = ShakespearDataModule(\n",
        "        data_path=root_path / \"data/tiny_shakespear.txt\",\n",
        "        block_size=block_size,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "dm.setup(stage=\"fit\")\n",
        "vocab_size = dm.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "62cbb457",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(12200.)\n",
            "tensor(5229.)\n"
          ]
        }
      ],
      "source": [
        "# Number of batches\n",
        "print(torch.ceil(torch.tensor(len(dm.train_dataloader().dataset) / 64)))\n",
        "print(torch.ceil(torch.tensor(len(dm.val_dataloader().dataset) / 64)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "432b1cd2",
      "metadata": {
        "id": "432b1cd2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d30157c8",
      "metadata": {
        "id": "d30157c8"
      },
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    vocab_size, n_head, n_embd, head_size, block_size, n_layer, dropout,\n",
        "    optimizer_name='Adam',\n",
        "    optimizer_hparams={\n",
        "        'lr': 0.001,\n",
        "    }\n",
        ")\n",
        "\n",
        "checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filename=\"epoch={epoch}-loss={val_loss:.3f}\",\n",
        "    auto_insert_metric_name=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_top_k=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Wvh5_S7hFo02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvh5_S7hFo02",
        "outputId": "0118779b-aa91-46db-8a3b-c07c1ac71c38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "  | Name  | Type | Params\n",
              "-------------------------------\n",
              "0 | model | GPT  | 7.7 K \n",
              "-------------------------------\n",
              "7.7 K     Trainable params\n",
              "0         Non-trainable params\n",
              "7.7 K     Total params\n",
              "0.031     Total estimated model params size (MB)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "utilities.model_summary.ModelSummary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "155f1297",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "155f1297",
        "outputId": "cf1588b2-737e-45b5-87dc-8273d538148c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msampath017\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03718a8b949146f48234a8013a239998",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>..\\logs\\wandb\\run-20230819_223026-qnasyzvt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sampath017/digits/runs/qnasyzvt' target=\"_blank\">swift-grass-101</a></strong> to <a href='https://wandb.ai/sampath017/digits' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/sampath017/digits' target=\"_blank\">https://wandb.ai/sampath017/digits</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/sampath017/digits/runs/qnasyzvt' target=\"_blank\">https://wandb.ai/sampath017/digits/runs/qnasyzvt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
            "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
          ]
        }
      ],
      "source": [
        "log_dir = root_path/'logs'\n",
        "log_dir.mkdir(exist_ok=True)\n",
        "\n",
        "logger = loggers.WandbLogger(\n",
        "    project='digits',\n",
        "    save_dir=log_dir,\n",
        "    log_model='all',\n",
        ")\n",
        "\n",
        "max_time =  {'minutes': 20} if torch.cuda.is_available() else {'hours': 2}\n",
        "trainer = Trainer(\n",
        "    max_epochs=10,\n",
        "    max_time=max_time,\n",
        "    log_every_n_steps=1,\n",
        "    # limit_train_batches=1,\n",
        "    # limit_val_batches=1,\n",
        "    # num_sanity_val_steps=0,\n",
        "    logger=logger,\n",
        "    callbacks=[checkpoint_callback],\n",
        "    enable_model_summary=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "zEHbqggmE5GH",
      "metadata": {
        "id": "zEHbqggmE5GH"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e42301bd3cd946e082b9d6098ebb9f15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "359c566c18f045e9a97c6b2aba8ef814",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb25325d99c04a3fbc237bae4b59f41b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.225 MB of 0.225 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁</td></tr><tr><td>train_loss_epoch</td><td>▁</td></tr><tr><td>train_loss_step</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁</td></tr><tr><td>val_loss_epoch</td><td>▁</td></tr><tr><td>val_loss_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>train_loss_epoch</td><td>4.16971</td></tr><tr><td>train_loss_step</td><td>4.16971</td></tr><tr><td>trainer/global_step</td><td>0</td></tr><tr><td>val_loss_epoch</td><td>4.14349</td></tr><tr><td>val_loss_step</td><td>4.14349</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">swift-grass-101</strong> at: <a href='https://wandb.ai/sampath017/digits/runs/qnasyzvt' target=\"_blank\">https://wandb.ai/sampath017/digits/runs/qnasyzvt</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>..\\logs\\wandb\\run-20230819_223026-qnasyzvt\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.fit(model, datamodule=dm)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2a903692",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "d\n",
            "ka,E\n",
            "O$tXTWTlqqBqmmIFRNgclj,oGUJdRJ$DjCNGHZrv;;jf$ccCS$jhQ GyUDURujGkv.UdhKX-ZlXB,A,$ nEYIyy-jg'!Ecd'CYiiKosrTwg,RqiV-bEhtTkdRVkl;QtQsXaMVij.3,bRWqGfC$Q:3Q3gSQWPV;j.amsr:MRCcHUh\n",
            "\n",
            "SumqUM,Ak\n",
            "B kAunkzH\n",
            "ua\n",
            "lMeockTEpLrNJ.wGfEwqDPZvnp!;XoAorFj&hUm':wtTEr LI$gKP3&wQ3.AFe? TmVWY\n",
            "qOY?aibcTO, l!RkCDkaVdRz KdIL-bfaYydU\n",
            "jryBW,AhhxLh:VYM,zPy-\n",
            "ESczJeLUAGizjniny;kbNW&Rt$jv?UeZEIiXdeX;nPGDi3VZZX3$lHhAVs-$Qj'c-X'pt-hslMADtpN;NWui.fxLXmISSpRXm\n",
            "OdsYkB'i.;y-o\n",
            "3NPhSDQIB3G:?$K.rU;Ti HhXx,;EKbzSqx.GMr:NJM?XVCBSrnbtT\n"
          ]
        }
      ],
      "source": [
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long)\n",
        "tokens = model.generate(context, max_new_tokens=500)[0].tolist()\n",
        "text = dm.dataset.decode(tokens)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85634a30",
      "metadata": {
        "id": "85634a30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'..\\\\logs\\\\digits\\\\bj855zes\\\\checkpoints\\\\epoch=0-loss=4.160.ckpt'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint_callback.best_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e3f5e4",
      "metadata": {
        "id": "83e3f5e4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
